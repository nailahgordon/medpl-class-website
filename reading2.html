<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Reading Response #2 – Cheikh Fall</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <h1>Reading Response #2</h1>
    <nav>
        <a href="index.html">Home</a>
        <a href="week1.html">Plato Reflection</a>
        <a href="image1.html">Image 1</a>
        <a href="image2.html">Image 2</a>
        <a href="depth.html">Depth of Field</a>
        <a href="blur.html">Blur Gallery</a>
        <a href="reading2.html">Reading #2</a>
    </nav>
</header>

<main>
    <h2>“AI slop” distorting our reality, the world is sleepwalking into disaster</h2>
    <p><strong>By Nesrine Malik</strong></p>

    <p>
        In her article about AI slop, Nesrine Malik argues that we are slowly letting artificial
        intelligence reshape our reality without really thinking about the consequences. She uses
        the term “AI slop” to describe the massive amount of low quality, AI generated content that
        is spreading across the internet. This includes images, videos, articles, and even fake news
        that look real at first glance. What stood out to me is that she is not just criticizing the
        technology itself. She is more concerned with how casually we are accepting it into our
        everyday lives.
    </p>

    <p>
        One of the strongest ideas in the article is when she suggests that society is “sleepwalking”
        into this situation. That word choice makes it feel like we are not fully aware of what is
        happening. AI tools are getting more advanced every day, and companies are pushing them
        because they save time and make money. But there is not enough discussion about what happens
        when fake content becomes impossible to tell apart from real content. If people cannot trust
        what they see online, that affects everything from politics to personal relationships.
    </p>

    <p>
        This connects directly to what we talk about in class about media shaping perception. Images
        and media have always influenced how we see the world, but now the scale is completely
        different. Before, editing a photo or creating fake media required skill and effort. Now it
        can be done in seconds. That changes how much power individuals have to manipulate information.
        If anyone can generate a realistic fake event, then proof does not mean the same thing anymore.
        That is honestly kind of unsettling.
    </p>

    <p>
        I also think the article forces us to reflect on our own role in all of this. It is easy to
        blame big tech companies, but regular users also contribute by sharing and engaging with content
        without questioning it. Social media rewards what gets attention, not what is accurate. If AI
        generated posts go viral, platforms will keep producing and promoting them. That cycle keeps
        repeating itself.
    </p>

    <p>
        Reading this made me more aware of how often I scroll without thinking. Sometimes something looks
        polished and professional, so I automatically assume it is real. Malik’s argument reminds us that
        we need stronger media literacy skills. We cannot just consume content passively anymore. We have
        to question where it came from and who benefits from it spreading.
    </p>

    <p>
        Overall, I see her article as a warning. She is not saying that AI is evil or that technology
        should stop developing. Instead, she is pointing out that if we do not slow down and think
        critically, we might lose our shared sense of reality. That feels especially important in a world
        where media already plays such a huge role in shaping culture and belief. If reality becomes
        flexible or constantly manipulated, trust becomes harder to maintain. That is what makes this
        issue more serious than it first appears.
    </p>
</main>

<footer>
    MEDPL 150 — Spring 2026
</footer>

</body>
</html>
